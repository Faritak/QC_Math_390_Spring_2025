{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1538b0-f92b-48b9-be07-e9527576bc8b",
   "metadata": {},
   "source": [
    "## Course Assignment Instructions\n",
    "You should have Python (version 3.8 or later) and Jupyter Notebook installed to complete this assignment. You will write code in the empty cell/cells below the problem. While most of this will be a programming assignment, some questions will ask you to \"write a few sentences\" in markdown cells. \n",
    "\n",
    "Submission Instructions:\n",
    "\n",
    "Create a labs directory in your personal class repository (e.g., located in your home directory)\n",
    "Clone the class repository\n",
    "Copy this Jupyter notebook file (.ipynb) into your repo/labs directory\n",
    "Make your edits, commit changes, and push to your repository\n",
    "All submissions must be pushed before the due date to avoid late penalties. \n",
    "\n",
    "Labs are graded out of a 100 pts. Each day late is -10. For a max penalty of -50 after 5 days. From there you may submit the lab anytime before the semester ends for a max score of 50.  \n",
    "\n",
    "Lab 5 is due on 3/17/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0e89f-550b-4278-90c1-5b4d73c3d088",
   "metadata": {},
   "source": [
    "Write a function spec'd as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923afa28-a1f6-46e8-bb9c-b51c427752b3",
   "metadata": {},
   "source": [
    "Provide predictions for each of these computations and then run them to make sure you're correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4881902d-f462-4164-ab3f-ea28f913814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norm_vec(x):\n",
    "    \"\"\"Compute the Euclidean norm of a vector.\"\"\"\n",
    "    return np.sqrt(np.sum(x**2))\n",
    "\n",
    "def orthogonal_projection(a, v):\n",
    "    \"\"\"\n",
    "    Projects vector a onto vector v.\n",
    "    \"\"\"\n",
    "    # Ensure numpy arrays\n",
    "    a = np.asarray(a)\n",
    "    v = np.asarray(v)\n",
    "    \n",
    "    # Compute the squared norm of v\n",
    "    v_norm_sq = norm_vec(v)**2\n",
    "    \n",
    "    # Create the projection matrix using outer product\n",
    "    H = np.outer(v, v) / v_norm_sq\n",
    "    \n",
    "    # Parallel and perpendicular components\n",
    "    a_parallel = H @ a\n",
    "    a_perpendicular = a - a_parallel\n",
    "    \n",
    "    return {'a_parallel': a_parallel, 'a_perpendicular': a_perpendicular}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf93752-a0a0-42e0-975a-43f01e967011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: orthogonal_projection([1,2,3,4], [1,2,3,4])\n",
      "a_parallel:\n",
      "[1. 2. 3. 4.]\n",
      "a_perpendicular:\n",
      "[0. 0. 0. 0.]\n",
      "\n",
      "Test 2: orthogonal_projection([1,2,3,4], [0,2,0,-1])\n",
      "a_parallel:\n",
      "[0. 0. 0. 0.]\n",
      "a_perpendicular:\n",
      "[1. 2. 3. 4.]\n",
      "\n",
      "Test 3: result = orthogonal_projection([2,6,7,3], [1,3,5,7]*37)\n",
      "Dot product (should be near 0): -3.552713678800501e-15\n",
      "Sum (should equal original vector [2,6,7,3]):\n",
      "[2. 6. 7. 3.]\n",
      "a_parallel divided by ([1,3,5,7]*37) (percentage of projection):\n",
      "[0.02445302 0.02445302 0.02445302 0.02445302]\n"
     ]
    }
   ],
   "source": [
    "# Test 1:\n",
    "print(\"Test 1: orthogonal_projection([1,2,3,4], [1,2,3,4])\")\n",
    "result1 = orthogonal_projection(np.array([1,2,3,4]), np.array([1,2,3,4]))\n",
    "print(\"a_parallel:\")\n",
    "print(result1['a_parallel'])        # Expected: [1, 2, 3, 4]\n",
    "print(\"a_perpendicular:\")\n",
    "print(result1['a_perpendicular'])     # Expected: [0, 0, 0, 0]\n",
    "\n",
    "\n",
    "# Test 2:\n",
    "print(\"\\nTest 2: orthogonal_projection([1,2,3,4], [0,2,0,-1])\")\n",
    "result2 = orthogonal_projection(np.array([1,2,3,4]), np.array([0,2,0,-1]))\n",
    "print(\"a_parallel:\")\n",
    "print(result2['a_parallel'])          # Expected: [0, 0, 0, 0]\n",
    "print(\"a_perpendicular:\")\n",
    "print(result2['a_perpendicular'])       # Expected: [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "# Test 3:\n",
    "print(\"\\nTest 3: result = orthogonal_projection([2,6,7,3], [1,3,5,7]*37)\")\n",
    "\n",
    "# Multiply [1,3,5,7] by 37\n",
    "v3 = np.array([1,3,5,7]) * 37\n",
    "result3 = orthogonal_projection(np.array([2,6,7,3]), v3)\n",
    "\n",
    "# Compute dot product between a_parallel and a_perpendicular (should be near 0)\n",
    "dot_product = np.dot(result3['a_parallel'], result3['a_perpendicular'])\n",
    "print(\"Dot product (should be near 0):\", dot_product)\n",
    "\n",
    "# Sum of parallel and perpendicular components should return the original vector\n",
    "sum_vector = result3['a_parallel'] + result3['a_perpendicular']\n",
    "print(\"Sum (should equal original vector [2,6,7,3]):\")\n",
    "print(sum_vector)\n",
    "\n",
    "# Compute the \"percentage\" of the projection relative to v3\n",
    "percentage = result3['a_parallel'] / v3\n",
    "print(\"a_parallel divided by ([1,3,5,7]*37) (percentage of projection):\")\n",
    "print(percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998085c4-9b18-402e-a8b4-4a91cc882b46",
   "metadata": {},
   "source": [
    "Create a vector y by simulating n = 100 standard iid normals. Create a matrix of size 100 x 2 and populate the first column by all ones (for the intercept) and the second column by 100 standard iid normals. Find the R^2 of an OLS regression of `y ~ X`. Use matrix algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1779d5-c6e5-4670-832a-a47634752b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSR: 127.2452490501258\n",
      "SST: 127.29265592243308\n",
      "R²: 0.00037242425310191063\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Simulate data\n",
    "n = 100\n",
    "y = np.random.randn(n, 1)  # y as a (100 x 1) column vector\n",
    "X = np.hstack((np.ones((n, 1)), np.random.randn(n, 1)))  # (100 x 2) design matrix\n",
    "\n",
    "# Compute OLS coefficients: beta_hat = (X'X)^(-1) X'y\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "\n",
    "# Compute the Hat matrix H = X (X'X)^(-1) X'\n",
    "H = X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "\n",
    "# Identity matrix\n",
    "I = np.eye(n)\n",
    "\n",
    "# Compute SSR (Residual Sum of Squares): SSR = y' (I - H) y\n",
    "SSR = (y.T @ (I - H) @ y).item()\n",
    "\n",
    "# Centering matrix: M = I - (1/n) * 11'\n",
    "M = I - (1/n) * np.ones((n, n))\n",
    "\n",
    "# Compute SST (Total Sum of Squares): SST = y' M y\n",
    "SST = (y.T @ M @ y).item()\n",
    "\n",
    "# Compute R²\n",
    "R2 = 1 - SSR / SST\n",
    "\n",
    "# Print results\n",
    "print(\"SSR:\", SSR)\n",
    "print(\"SST:\", SST)\n",
    "print(\"R²:\", R2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b19394-0558-4670-86e0-2d9295ae1243",
   "metadata": {},
   "source": [
    "Write a for loop to each time bind a new column of 100 standard iid normals to the matrix X and find the R^2 each time until the number of columns is 100. Create a vector to save all R^2's. What happened??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736b27a0-df6f-447c-8e78-f3c443e2e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² values for models with 1 to 100 columns:\n",
      "[0.0, 0.00037242425310191063, 0.0039534712234703395, 0.015515917195883855, 0.016012956955489988, 0.060483757420479956, 0.0604856345047039, 0.06791713923101828, 0.1155205486782005, 0.115985431479941, 0.162531991451342, 0.16324852246361632, 0.1653058735950539, 0.16726405487373353, 0.16959752126125316, 0.186791654654901, 0.18680390934298918, 0.19280704730131826, 0.19656454956494696, 0.20676806135980885, 0.2067805910051016, 0.21297298468610137, 0.21413227261249568, 0.22344231007274185, 0.2644021621922207, 0.2688518991099367, 0.290450808990139, 0.29132140616382185, 0.2940661523691507, 0.29505341769528637, 0.3224612676383529, 0.34069205476632747, 0.34966372664455925, 0.36519299490256085, 0.36609673260436104, 0.38741665786176305, 0.403060815708544, 0.40637996512050323, 0.4084185281712275, 0.4086532629450571, 0.4087302243058517, 0.4122560226143148, 0.4199723297044975, 0.45296272233899937, 0.45435748259751674, 0.45838951359740276, 0.4584411626637773, 0.4587105682059598, 0.45982371981347814, 0.4600827673875302, 0.46421557720102713, 0.46568539273667275, 0.4740253125991649, 0.4759792162552864, 0.4767914615445271, 0.478609966753774, 0.4838485658728213, 0.4841312500428515, 0.48610209078091626, 0.48632682326221566, 0.48719767430164607, 0.487272657603376, 0.48810957144301825, 0.49143361543092023, 0.5026734179392027, 0.5218393708002694, 0.5226854273997588, 0.5306612598397727, 0.5400117729727334, 0.5758618965548252, 0.5794672894601183, 0.5825674203353446, 0.5833897760854552, 0.597785586429479, 0.6020719460622731, 0.6329237023727555, 0.6428928919050505, 0.6792167766016535, 0.6804377097045042, 0.6836940953170598, 0.6877262170318659, 0.6958153024269471, 0.6959141060332985, 0.8269638581828745, 0.8269642644890395, 0.8421062351150496, 0.8511300271839719, 0.8526653897465583, 0.8912768916579414, 0.8935047892458806, 0.9170216179578101, 0.9194927487245199, 0.9198619785829011, 0.9290091629043679, 0.9358374484878512, 0.9528344080343919, 0.969436419641471, 0.9746421719572972, 0.998360377510893, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set seed again for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Simulate response variable\n",
    "n = 100\n",
    "y = np.random.randn(n)  # y as a flat 1D array\n",
    "\n",
    "# Start with intercept-only matrix (n x 1)\n",
    "X = np.ones((n, 1))\n",
    "\n",
    "# Pre-allocate list to save R² values\n",
    "R2_list = []\n",
    "\n",
    "# Loop: each time add a new column\n",
    "for i in range(100):\n",
    "    if i > 0:\n",
    "        new_col = np.random.randn(n, 1)\n",
    "        X = np.hstack((X, new_col))\n",
    "    \n",
    "    # Fit OLS using normal equation\n",
    "    beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "    \n",
    "    # Fitted values\n",
    "    y_hat = X @ beta_hat\n",
    "    \n",
    "    # Calculate SST and SSR\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    SSR = np.sum((y - y_hat)**2)\n",
    "    \n",
    "    # Calculate R²\n",
    "    R2 = 1 - SSR / SST\n",
    "    R2_list.append(R2)\n",
    "\n",
    "# Print R² values\n",
    "print(\"R² values for models with 1 to 100 columns:\")\n",
    "print(R2_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81287175-3680-42bb-9125-67b175c53424",
   "metadata": {},
   "source": [
    "What happened? As more predictors are added, even if they are just noise, the R2 generally increases, relfecting that the model is overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99824f-7049-4057-bfa8-5659a13e3aa4",
   "metadata": {},
   "source": [
    "Test that the projection matrix onto this X is the same as I_n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f24d3f-c93d-4104-937d-e4ec12a072e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection matrix P equals the identity matrix I_n.\n"
     ]
    }
   ],
   "source": [
    "# Compute the projection matrix P = X (X'X)^(-1) X'\n",
    "P = X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "\n",
    "# Define the identity matrix I_n\n",
    "I_n = np.eye(n)\n",
    "\n",
    "# Test if P is (numerically) equal to I_n\n",
    "if np.allclose(P, I_n):\n",
    "    print(\"Projection matrix P equals the identity matrix I_n.\")\n",
    "else:\n",
    "    print(\"Projection matrix P does NOT equal the identity matrix I_n.\")\n",
    "\n",
    "# Optional: use an assertion for automatic checking\n",
    "assert np.allclose(P, I_n), \"Projection matrix does not equal identity matrix!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877001c-87e9-46f6-ae2f-29a265b9ba43",
   "metadata": {},
   "source": [
    "Add one final column to X to bring the number of columns to 101. Then try to compute R^2. What happens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb942568-2bf2-4960-99dc-37a2c39d5a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.713290675962704\n"
     ]
    }
   ],
   "source": [
    "# Add one extra random column\n",
    "extra_col = np.random.randn(n, 1)\n",
    "\n",
    "# Bind it to X to make X_new (100 x 101)\n",
    "X_new = np.hstack((X, extra_col))\n",
    "\n",
    "# Try to compute beta_hat\n",
    "try:\n",
    "    beta_hat = np.linalg.inv(X_new.T @ X_new) @ (X_new.T @ y)\n",
    "    y_hat = X_new @ beta_hat\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    SSR = np.sum((y - y_hat)**2)\n",
    "    R2 = 1 - SSR / SST\n",
    "    print(\"R²:\", R2)\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print(\"Error in computing beta_hat:\", e)\n",
    "    print(\"Could not compute R² because X'X is singular.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2564094-7ac8-4061-adea-fbdaa1a79a82",
   "metadata": {},
   "source": [
    "Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b14cc-d0b1-4d19-9633-1cdff50bf579",
   "metadata": {},
   "source": [
    "You cannot fit a full model when p > n because there’s too much flexibility and not enough data to estimate all parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d693a-5e8d-4efd-8dd7-ee5b840584b9",
   "metadata": {},
   "source": [
    "Let's use the Boston Housing Data for the following exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9e3875-f26e-4e36-addb-dc79442a6fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictors (including intercept): 14\n",
      "Number of observations: 506\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the Boston housing data\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=r\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "# The dataset format:\n",
    "# - Every 2 rows = 1 observation\n",
    "# - First row: first 13 predictors\n",
    "# - Second row: 2 predictors + response (medv)\n",
    "\n",
    "# Assemble the full predictor matrix\n",
    "X_data = np.hstack([\n",
    "    raw_df.values[::2, :],      # Rows 0,2,4,... (first 13 predictors)\n",
    "    raw_df.values[1::2, :2]     # Rows 1,3,5,... (first two values of second row)\n",
    "])\n",
    "\n",
    "# Response vector y (3rd column of second rows)\n",
    "y = raw_df.values[1::2, 2]\n",
    "\n",
    "# Add an intercept column\n",
    "X = sm.add_constant(X_data)\n",
    "\n",
    "# Number of predictors (+1 for intercept) and observations\n",
    "p_plus_one = X.shape[1]\n",
    "n = X.shape[0]\n",
    "\n",
    "print(\"Number of predictors (including intercept):\", p_plus_one)\n",
    "print(\"Number of observations:\", n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c1a4b-da46-4b6d-a118-6d555303ef15",
   "metadata": {},
   "source": [
    "Using your function `orthogonal_projection` orthogonally project onto the column space of X by projecting y on each vector of X individually and adding up the projections and call the sum `yhat_naive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6877ea9-b7b7-45a0-a7aa-e3eea9911088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few entries of yhat_naive:\n",
      "[177.34253286 185.60133556 177.71752148 171.72473472 177.32548791]\n"
     ]
    }
   ],
   "source": [
    "# Assume y, X, and orthogonal_projection() are already loaded\n",
    "\n",
    "# Initialize yhat_naive as a zero vector (same shape as y)\n",
    "yhat_naive = np.zeros_like(y)\n",
    "\n",
    "# Project y onto each column of X individually and sum\n",
    "for j in range(X.shape[1]):\n",
    "    proj = orthogonal_projection(y, X[:, j])\n",
    "    yhat_naive += proj['a_parallel']\n",
    "\n",
    "# Inspect\n",
    "print(\"First few entries of yhat_naive:\")\n",
    "print(yhat_naive[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46e13e-3846-4cae-904e-05db448815fb",
   "metadata": {},
   "source": [
    "How much double counting occurred? Measure the magnitude relative to the true LS orthogonal projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b81a208-d76e-4b52-9df6-d828148b6f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude ratio (sqrt(sum(yhat_naive^2)) / sqrt(sum(yhat^2))): 8.997117717661752\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 1. Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# 2. Extract the true OLS fitted values\n",
    "yhat = model.fittedvalues\n",
    "\n",
    "# 3. Compute the magnitude ratio\n",
    "mag_ratio = np.sqrt(np.sum(yhat_naive**2)) / np.sqrt(np.sum(yhat**2))\n",
    "\n",
    "# 4. Print\n",
    "print(\"Magnitude ratio (sqrt(sum(yhat_naive^2)) / sqrt(sum(yhat^2))):\", mag_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db340f11-194f-4236-9eb4-b02385a62027",
   "metadata": {},
   "source": [
    "Is this ratio expected? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf111525-6ff3-4f23-a2b0-ee48e8fdba59",
   "metadata": {},
   "source": [
    "In summary, the ratio is expected to deviate from 1 because the sum of individual (non-orthogonal) projections overestimates the overall projection onto the column space, leading to a larger magnitude for the naive projection compared to the true LS projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61bf97-44ee-41ac-a3bb-ccbebb3c3dd5",
   "metadata": {},
   "source": [
    "Convert X into V where V has the same column space as X but has orthogonal columns. You can use the function `orthogonal_projection`. This is the Gram-Schmidt orthogonalization algorithm (part A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7c953a6-710b-4565-83b2-08c651f92490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize V to hold the orthogonalized columns\n",
    "V = np.empty_like(X)\n",
    "\n",
    "# The first column of V is simply the first column of X\n",
    "V[:, 0] = X[:, 0]\n",
    "\n",
    "# Orthogonalize remaining columns\n",
    "for j in range(1, X.shape[1]):\n",
    "    V[:, j] = X[:, j].copy()\n",
    "    for k in range(j):\n",
    "        proj = orthogonal_projection(V[:, j], V[:, k])\n",
    "        V[:, j] = V[:, j] - proj['a_parallel']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ba41e-ec46-4966-9ae2-30b95dcd322b",
   "metadata": {},
   "source": [
    "Convert V into Q whose columns are the same except normalized. This is the Gram-Schmidt orthogonalization algorithm (part B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f9bbc2e-bacb-4106-856a-74013615c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few entries of Q:\n",
      "[[ 0.04445542 -0.01866158  0.00910601 -0.05766684 -0.00830254]\n",
      " [ 0.04445542 -0.01855299 -0.02592754 -0.03907578 -0.01166524]\n",
      " [ 0.04445542 -0.0185531  -0.02592756 -0.03907574 -0.01166525]\n",
      " [ 0.04445542 -0.01852682 -0.02592218 -0.07931947 -0.00856873]\n",
      " [ 0.04445542 -0.01833705 -0.02588335 -0.07939459 -0.00855013]]\n"
     ]
    }
   ],
   "source": [
    "# Create Q by normalizing each column of V\n",
    "Q = np.empty_like(V)\n",
    "\n",
    "for j in range(V.shape[1]):\n",
    "    Q[:, j] = V[:, j] / norm_vec(V[:, j])\n",
    "\n",
    "# (Optional) If you want to clean memory\n",
    "del V\n",
    "\n",
    "# Verify first few columns if you like\n",
    "print(\"First few entries of Q:\")\n",
    "print(Q[:5, :5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587a626-aae5-4295-81a4-c014d55a0441",
   "metadata": {},
   "source": [
    "Verify Q^T Q is I_{p+1} i.e. Q is an orthonormal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c70bb05-8afa-4f6d-9e6e-6c365a113ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QᵀQ equals the identity matrix, Q is orthonormal.\n",
      "Difference between QᵀQ and Identity:\n",
      "[[-4.10782519e-15 -2.77555756e-16  6.24500451e-17  2.63677968e-15\n",
      "  -1.90819582e-17 -3.85802501e-15  7.58074159e-16  2.49800181e-15\n",
      "   1.67921232e-15 -5.27355937e-16 -6.58847976e-15  4.71844785e-16\n",
      "  -1.81105131e-15 -1.50573998e-15]\n",
      " [-2.77555756e-16 -1.11022302e-16  1.99493200e-17 -6.93889390e-18\n",
      "  -9.43255890e-18  2.08166817e-17  2.03830008e-17 -5.20417043e-17\n",
      "   5.72458747e-17  6.93889390e-18 -8.23993651e-17  4.59701721e-17\n",
      "   1.45283091e-16  3.20923843e-17]\n",
      " [ 6.24500451e-17  1.99493200e-17 -2.22044605e-16  1.87350135e-16\n",
      "   2.08166817e-17  6.24500451e-17 -3.12250226e-17  1.04083409e-16\n",
      "  -8.67361738e-17  0.00000000e+00 -7.63278329e-17  1.38777878e-16\n",
      "  -2.08166817e-17 -1.30104261e-18]\n",
      " [ 2.63677968e-15 -6.93889390e-18  1.87350135e-16  6.66133815e-16\n",
      "   2.60208521e-17  1.97758476e-16 -1.18394877e-16  4.85722573e-17\n",
      "  -6.43473989e-17 -5.55111512e-17  8.32667268e-17  6.93889390e-17\n",
      "  -5.20417043e-17  4.16333634e-17]\n",
      " [-1.90819582e-17 -9.43255890e-18  2.08166817e-17  2.60208521e-17\n",
      "  -1.11022302e-16 -5.37764278e-17 -6.93889390e-18  3.12250226e-17\n",
      "  -1.73472348e-17  4.08744219e-17  1.56125113e-17  2.77555756e-17\n",
      "   1.04083409e-17  4.16333634e-17]\n",
      " [-3.85802501e-15  2.08166817e-17  6.24500451e-17  1.97758476e-16\n",
      "  -5.37764278e-17  0.00000000e+00  4.16333634e-17  8.67361738e-17\n",
      "   1.73472348e-17  1.11022302e-16  8.32667268e-17  6.93889390e-18\n",
      "   0.00000000e+00  2.42861287e-17]\n",
      " [ 7.58074159e-16  2.03830008e-17 -3.12250226e-17 -1.18394877e-16\n",
      "  -6.93889390e-18  4.16333634e-17 -1.11022302e-16  2.12503626e-17\n",
      "   1.38777878e-17  1.12757026e-17  1.73472348e-17  7.28583860e-17\n",
      "  -3.46944695e-18  1.24900090e-16]\n",
      " [ 2.49800181e-15 -5.20417043e-17  1.04083409e-16  4.85722573e-17\n",
      "   3.12250226e-17  8.67361738e-17  2.12503626e-17  2.22044605e-16\n",
      "  -1.38777878e-17 -3.46944695e-18 -5.20417043e-18  2.08166817e-17\n",
      "   1.69135539e-17 -2.08166817e-17]\n",
      " [ 1.67921232e-15  5.72458747e-17 -8.67361738e-17 -6.43473989e-17\n",
      "  -1.73472348e-17  1.73472348e-17  1.38777878e-17 -1.38777878e-17\n",
      "   2.22044605e-16 -1.73472348e-18 -2.77555756e-17  3.46944695e-17\n",
      "   8.45677695e-18  2.25514052e-17]\n",
      " [-5.27355937e-16  6.93889390e-18  0.00000000e+00 -5.55111512e-17\n",
      "   4.08744219e-17  1.11022302e-16  1.12757026e-17 -3.46944695e-18\n",
      "  -1.73472348e-18 -6.66133815e-16  4.71844785e-16  1.59594560e-16\n",
      "  -3.81639165e-17  2.16840434e-17]\n",
      " [-6.58847976e-15 -8.23993651e-17 -7.63278329e-17  8.32667268e-17\n",
      "   1.56125113e-17  8.32667268e-17  1.73472348e-17 -5.20417043e-18\n",
      "  -2.77555756e-17  4.71844785e-16 -8.88178420e-16  3.12250226e-17\n",
      "  -4.33680869e-18 -2.08166817e-17]\n",
      " [ 4.71844785e-16  4.59701721e-17  1.38777878e-16  6.93889390e-17\n",
      "   2.77555756e-17  6.93889390e-18  7.28583860e-17  2.08166817e-17\n",
      "   3.46944695e-17  1.59594560e-16  3.12250226e-17 -2.22044605e-16\n",
      "   2.10335221e-17  2.08166817e-17]\n",
      " [-1.81105131e-15  1.45283091e-16 -2.08166817e-17 -5.20417043e-17\n",
      "   1.04083409e-17  0.00000000e+00 -3.46944695e-18  1.69135539e-17\n",
      "   8.45677695e-18 -3.81639165e-17 -4.33680869e-18  2.10335221e-17\n",
      "   4.44089210e-16 -3.46944695e-18]\n",
      " [-1.50573998e-15  3.20923843e-17 -1.30104261e-18  4.16333634e-17\n",
      "   4.16333634e-17  2.42861287e-17  1.24900090e-16 -2.08166817e-17\n",
      "   2.25514052e-17  2.16840434e-17 -2.08166817e-17  2.08166817e-17\n",
      "  -3.46944695e-18 -3.33066907e-16]]\n"
     ]
    }
   ],
   "source": [
    "# Compute QᵀQ\n",
    "QtQ = Q.T @ Q\n",
    "\n",
    "# Identity matrix\n",
    "I_p = np.eye(Q.shape[1])\n",
    "\n",
    "# Check if QᵀQ ≈ Identity matrix\n",
    "if np.allclose(QtQ, I_p):\n",
    "    print(\"QᵀQ equals the identity matrix, Q is orthonormal.\")\n",
    "else:\n",
    "    print(\"QᵀQ does NOT equal the identity matrix!\")\n",
    "    \n",
    "# Optionally print difference\n",
    "print(\"Difference between QᵀQ and Identity:\")\n",
    "print(QtQ - I_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad012fab-f233-4a7d-b8b4-c7d5030b1f97",
   "metadata": {},
   "source": [
    "Is your Q the same as what results from R's built-in QR-decomposition function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26df14a5-db7d-4baf-bf3f-ac11a70521fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q matches the built-in QR decomposition Q (up to sign differences).\n",
      "Difference (absolute values):\n",
      "[[-1.38777878e-17 -1.73472348e-17 -2.77555756e-17 ...  2.13162821e-14\n",
      "  -3.25000443e-15 -2.90739655e-15]\n",
      " [ 0.00000000e+00  1.07552856e-16 -3.46944695e-18 ... -1.17961196e-16\n",
      "  -5.78963960e-17  2.46330734e-16]\n",
      " [ 0.00000000e+00  1.04083409e-17  4.16333634e-17 ... -6.93889390e-17\n",
      "  -6.11490025e-17  1.52655666e-16]\n",
      " ...\n",
      " [ 0.00000000e+00  6.93889390e-18  0.00000000e+00 ...  6.93889390e-17\n",
      "  -8.06646416e-17  2.22044605e-16]\n",
      " [ 0.00000000e+00 -6.93889390e-18  0.00000000e+00 ...  0.00000000e+00\n",
      "  -1.85615412e-16 -4.16333634e-17]\n",
      " [ 0.00000000e+00 -6.93889390e-18 -3.46944695e-18 ...  2.77555756e-17\n",
      "  -1.87350135e-16 -2.77555756e-17]]\n"
     ]
    }
   ],
   "source": [
    "Q_builtin, R = np.linalg.qr(X)\n",
    "\n",
    "if np.allclose(np.abs(Q), np.abs(Q_builtin)):\n",
    "    print(\"Q matches the built-in QR decomposition Q (up to sign differences).\")\n",
    "else:\n",
    "    print(\"Q does not match the built-in QR decomposition Q.\")\n",
    "\n",
    "print(\"Difference (absolute values):\")\n",
    "print(np.abs(Q) - np.abs(Q_builtin))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ac792-5397-437d-9282-6516ae05e7e2",
   "metadata": {},
   "source": [
    "Is this expected? Why did this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee2c88-f5dc-4c7d-8241-eb9f2295c407",
   "metadata": {},
   "source": [
    "Yes this is expected because there are an infinite number of orthonormal basis of any column space and the likelihood of them being equal is highly unlikely.  \n",
    "There are many different orthonormal basis of any column space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91635448-669c-4f1a-ab75-4fe76c5f339a",
   "metadata": {},
   "source": [
    "Project y onto colsp[Q] and verify it is the same as the OLS fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a6ddf2c-c1bb-4c6a-8023-e2e7666ad9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of y onto colsp[Q] equals the OLS fit.\n",
      "Difference (y_hat_from_Q - yhat):\n",
      "[-2.77111667e-13  2.27373675e-13  1.42108547e-13  1.77635684e-14\n",
      "  3.55271368e-14  8.17124146e-14  6.75015599e-14  2.09610107e-13\n",
      "  1.68753900e-13  1.98951966e-13  2.06057393e-13  1.95399252e-13\n",
      " -1.17239551e-13  1.77635684e-14  1.38555833e-13 -3.55271368e-14\n",
      " -1.70530257e-13  6.75015599e-14 -1.17239551e-13  3.55271368e-15\n",
      "  1.15463195e-13  1.13686838e-13  6.92779167e-14  1.24344979e-13\n",
      "  1.36779477e-13  1.59872116e-13  1.54543045e-13  1.68753900e-13\n",
      "  1.66977543e-13  1.13686838e-13  9.94759830e-14  2.06057393e-13\n",
      "  7.10542736e-14  1.29674049e-13  2.06057393e-13  2.84217094e-14\n",
      " -7.10542736e-15 -9.94759830e-14 -1.84741111e-13  2.13162821e-14\n",
      "  0.00000000e+00 -9.59232693e-14 -7.10542736e-14 -1.06581410e-13\n",
      "  1.03028697e-13  2.84217094e-14 -1.06581410e-14  2.91322522e-13\n",
      "  2.57571742e-13  1.88293825e-13  1.56319402e-13  2.91322522e-13\n",
      "  5.32907052e-14  4.61852778e-14 -3.01980663e-13  2.77111667e-13\n",
      "  1.42108547e-14  3.19744231e-13  1.77635684e-13  2.27373675e-13\n",
      "  3.26849658e-13  4.76063633e-13  3.73034936e-13  2.38031816e-13\n",
      "  2.48689958e-13 -9.94759830e-14 -4.97379915e-14 -1.91846539e-13\n",
      " -1.45661261e-13 -1.31450406e-13 -5.32907052e-14  3.55271368e-15\n",
      " -2.48689958e-14 -5.32907052e-14 -2.62900812e-13 -2.48689958e-14\n",
      "  1.17239551e-13 -4.61852778e-14  2.13162821e-14 -8.17124146e-14\n",
      " -2.13162821e-14  1.95399252e-13 -2.84217094e-14  5.32907052e-14\n",
      " -3.90798505e-14  1.77635684e-14 -9.59232693e-14 -1.77635684e-14\n",
      " -2.13162821e-14 -1.63424829e-13 -1.74082970e-13 -1.24344979e-13\n",
      "  4.40536496e-13  3.01980663e-13  5.57776048e-13 -1.56319402e-13\n",
      " -1.45661261e-13 -9.23705556e-14 -3.19744231e-13 -1.70530257e-13\n",
      " -1.10134124e-13 -1.45661261e-13  1.74082970e-13 -9.23705556e-14\n",
      " -8.52651283e-14 -8.52651283e-14 -1.20792265e-13 -1.38555833e-13\n",
      " -3.90798505e-14 -9.94759830e-14 -2.87769808e-13 -1.91846539e-13\n",
      " -1.74082970e-13 -1.63424829e-13 -1.77635684e-13 -1.56319402e-13\n",
      " -2.41584530e-13 -1.70530257e-13 -2.30926389e-13 -2.94875235e-13\n",
      "  8.41993142e-13  9.27258270e-13  9.45021839e-13  9.09494702e-13\n",
      "  9.87654403e-13  9.59232693e-13  8.95283847e-13  1.91846539e-13\n",
      "  2.02504680e-13  1.74082970e-13  2.45137244e-13  2.48689958e-13\n",
      "  2.70006240e-13  2.25597319e-13  3.21520588e-13  2.02504680e-13\n",
      "  1.90070182e-13  2.16715534e-13  1.54543045e-13  1.70530257e-13\n",
      "  9.76996262e-14  5.32907052e-14 -2.00728323e-13 -1.43884904e-13\n",
      " -1.59872116e-13  1.77635684e-14  1.36779477e-13 -1.58095759e-13\n",
      " -1.42108547e-13 -8.17124146e-14 -2.48689958e-14  2.84217094e-14\n",
      " -9.23705556e-14  6.03961325e-14 -5.32907052e-14  4.26325641e-14\n",
      "  1.75859327e-13  3.05533376e-13  3.26849658e-13  5.68434189e-14\n",
      "  2.34479103e-13  2.77111667e-13  2.55795385e-13  2.20268248e-13\n",
      "  2.30926389e-13  3.69482223e-13  2.98427949e-13  2.80664381e-13\n",
      "  3.23296945e-13  2.84217094e-13  3.09086090e-13  2.94875235e-13\n",
      " -7.46069873e-14 -6.39488462e-14 -1.56319402e-13 -3.09086090e-13\n",
      " -2.52242671e-13 -6.39488462e-14 -1.03028697e-13 -2.13162821e-14\n",
      "  9.23705556e-14 -2.84217094e-14  1.77635684e-13  2.02504680e-13\n",
      "  1.27897692e-13  1.06581410e-14 -3.55271368e-14 -3.62376795e-13\n",
      " -3.69482223e-13 -3.41060513e-13 -3.44613227e-13 -2.84217094e-13\n",
      " -3.12638804e-13 -1.63424829e-13 -8.17124146e-14  7.10542736e-15\n",
      " -1.20792265e-13 -1.13686838e-13 -1.13686838e-13 -3.19744231e-13\n",
      " -3.16191517e-13 -1.77635684e-13 -2.98427949e-13  2.06057393e-13\n",
      "  2.20268248e-13 -6.75015599e-14  1.35003120e-13  2.06057393e-13\n",
      "  9.94759830e-14  2.41584530e-13  2.41584530e-13  1.56319402e-13\n",
      "  1.06581410e-14  1.06581410e-14 -2.68229883e-13  6.75015599e-14\n",
      "  1.20792265e-13  4.05009359e-13  3.01980663e-13  3.80140364e-13\n",
      "  7.81597009e-14  1.42108547e-14  2.84217094e-14  1.24344979e-13\n",
      "  1.06581410e-13  1.27897692e-13  1.77635684e-13  1.35003120e-13\n",
      " -2.27373675e-13 -1.81188398e-13  5.68434189e-14  1.42108547e-13\n",
      "  1.20792265e-13  9.23705556e-14  2.13162821e-14  2.13162821e-14\n",
      "  6.75015599e-14  1.35003120e-13 -4.61852778e-14  7.10542736e-14\n",
      "  1.24344979e-13  1.77635684e-13  1.66977543e-13 -6.39488462e-14\n",
      "  3.26849658e-13  2.34479103e-13  8.88178420e-14  3.55271368e-13\n",
      "  1.74082970e-13 -2.13162821e-14 -6.39488462e-14 -2.48689958e-14\n",
      "  1.42108547e-14 -2.48689958e-14  7.46069873e-14 -2.84217094e-14\n",
      "  2.62900812e-13 -9.23705556e-14 -7.10542736e-15  7.10542736e-15\n",
      " -1.20792265e-13 -5.68434189e-14 -4.26325641e-14 -6.39488462e-14\n",
      " -5.68434189e-14 -2.30926389e-13 -1.49213975e-13 -1.42108547e-13\n",
      " -1.70530257e-13  1.27897692e-13  1.03028697e-13 -1.77635684e-14\n",
      "  2.09610107e-13  1.20792265e-13  2.13162821e-14  1.49213975e-13\n",
      "  1.20792265e-13  2.13162821e-14  6.03961325e-14 -7.10542736e-15\n",
      "  2.27373675e-13  7.81597009e-14  1.06581410e-13  2.84217094e-14\n",
      " -3.19744231e-14 -1.20792265e-13  1.77635684e-13  1.81188398e-13\n",
      "  2.55795385e-13  1.24344979e-13  2.20268248e-13  2.13162821e-13\n",
      "  1.88293825e-13  1.38555833e-13  2.59348099e-13  2.38031816e-13\n",
      "  3.62376795e-13  3.48165941e-13 -1.20792265e-13 -1.91846539e-13\n",
      "  1.42108547e-14  1.77635684e-14 -9.94759830e-14 -7.81597009e-14\n",
      "  6.39488462e-14  1.35003120e-13  2.20268248e-13  2.13162821e-13\n",
      "  1.66977543e-13  8.17124146e-14 -1.49213975e-13 -4.97379915e-14\n",
      "  1.31450406e-13  1.49213975e-13  1.63424829e-13  1.20792265e-13\n",
      "  9.59232693e-14  3.90798505e-14  3.90798505e-14 -7.10542736e-15\n",
      "  4.26325641e-14  6.03961325e-14  3.55271368e-14  1.52766688e-13\n",
      " -1.42108547e-14 -1.35003120e-13 -5.68434189e-14 -1.06581410e-14\n",
      " -6.64357458e-13 -6.89226454e-13 -5.79092330e-13 -1.45661261e-13\n",
      " -1.20792265e-13  1.13686838e-13  1.13686838e-13  4.97379915e-14\n",
      "  6.39488462e-14  1.66977543e-13  7.10542736e-15  4.61852778e-14\n",
      "  1.31450406e-13 -1.24344979e-13 -6.07514039e-13 -1.06581410e-13\n",
      " -2.16715534e-13 -1.66977543e-13 -1.35003120e-13  2.48689958e-14\n",
      "  1.10134124e-13 -2.09610107e-13 -1.49213975e-13 -1.10134124e-13\n",
      " -2.48689958e-13  6.60804744e-13  7.10542736e-14  7.46069873e-14\n",
      " -8.88178420e-14 -9.23705556e-14 -1.17239551e-13 -8.17124146e-14\n",
      "  1.42108547e-14 -1.06581410e-14  3.19744231e-14 -9.94759830e-14\n",
      " -5.68434189e-14  8.88178420e-14  5.50670620e-14  3.55271368e-13\n",
      "  2.16715534e-13  1.13686838e-13  9.94759830e-14  1.45661261e-13\n",
      "  7.10542736e-15 -1.11022302e-13 -1.27897692e-13  3.55271368e-14\n",
      " -4.97379915e-14 -2.48689958e-14 -3.01980663e-14  1.42108547e-14\n",
      " -5.86197757e-14 -1.06581410e-14 -3.37507799e-14 -4.08562073e-14\n",
      " -4.88498131e-14 -1.15463195e-13 -7.01660952e-14 -1.70530257e-13\n",
      " -6.83897383e-14 -8.88178420e-15  1.06581410e-14 -7.10542736e-14\n",
      " -5.50670620e-14  0.00000000e+00  0.00000000e+00  1.77635684e-14\n",
      " -2.48689958e-14  3.55271368e-15 -9.41469125e-14 -1.66977543e-13\n",
      " -6.75015599e-14 -1.06581410e-14  1.06581410e-14 -2.66453526e-14\n",
      " -9.76996262e-14 -3.55271368e-14  2.48689958e-14  1.31450406e-13\n",
      "  8.88178420e-14  2.41584530e-13  4.60076421e-13  3.48165941e-13\n",
      "  2.68229883e-13  2.30926389e-13  1.04805054e-13  2.20268248e-13\n",
      "  2.04281037e-13  1.06581410e-13  2.93098879e-13  7.10542736e-14\n",
      "  7.46069873e-14  5.32907052e-14  1.45661261e-13  2.85993451e-13\n",
      "  2.80664381e-13  2.62900812e-13  2.06057393e-13  2.23820962e-13\n",
      "  1.20792265e-13  2.20268248e-13  2.98427949e-13  3.19744231e-13\n",
      "  2.73558953e-13  1.95399252e-13  2.43360887e-13  1.31450406e-13\n",
      "  2.34479103e-13  2.14939178e-13  3.55271368e-14 -9.23705556e-14\n",
      " -9.05941988e-14 -4.26325641e-14  3.55271368e-15 -1.77635684e-14\n",
      "  4.08562073e-14  1.81188398e-13  2.84217094e-14 -3.55271368e-15\n",
      "  7.10542736e-15  7.10542736e-14  2.87769808e-13  4.26325641e-14\n",
      " -1.06581410e-14  3.90798505e-14  2.93098879e-13  2.06057393e-13\n",
      "  2.62900812e-13  2.52242671e-13  5.68434189e-14 -2.13162821e-14\n",
      "  9.59232693e-14  0.00000000e+00 -2.84217094e-14  3.55271368e-14\n",
      " -6.39488462e-14 -1.06581410e-13  3.19744231e-13  1.52766688e-13\n",
      "  2.48689958e-14 -6.03961325e-14  1.06581410e-13  2.16715534e-13\n",
      "  6.03961325e-14 -3.55271368e-15  1.63424829e-13  1.42108547e-13\n",
      "  6.75015599e-14  8.88178420e-14  9.59232693e-14  8.17124146e-14\n",
      "  9.59232693e-14  1.63424829e-13  1.77635684e-13 -1.42108547e-14\n",
      " -7.81597009e-14 -1.06581410e-14  1.13686838e-13 -2.48689958e-14\n",
      " -3.07309733e-13 -2.78888024e-13 -3.10862447e-13 -2.73558953e-13\n",
      " -3.25073302e-13 -3.01980663e-13 -3.94351218e-13 -4.79616347e-13\n",
      " -2.48689958e-13 -1.98951966e-13 -2.48689958e-13 -2.13162821e-13\n",
      " -1.66977543e-13  6.75015599e-14  1.10134124e-13  2.13162821e-13\n",
      "  2.23820962e-13  1.81188398e-13]\n"
     ]
    }
   ],
   "source": [
    "# Project y onto colsp[Q]: since Q is orthonormal, projection is Q @ Qᵀ @ y\n",
    "y_hat_from_Q = Q @ (Q.T @ y)\n",
    "\n",
    "# Compare to true OLS fitted values\n",
    "if np.allclose(y_hat_from_Q, yhat):\n",
    "    print(\"The projection of y onto colsp[Q] equals the OLS fit.\")\n",
    "else:\n",
    "    print(\"There is a discrepancy between the projection and the OLS fit.\")\n",
    "\n",
    "# Optionally, print the small difference\n",
    "print(\"Difference (y_hat_from_Q - yhat):\")\n",
    "print(y_hat_from_Q - yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33be031-6ec3-4d45-b74c-baf3269d0997",
   "metadata": {},
   "source": [
    "Project y onto colsp[Q] one by one and verify it sums to be the projection onto the whole space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17ec740d-6bd8-4155-ad3d-203a277984ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive projection (one column at a time) equals the full projection (Q @ Qᵀ @ y).\n",
      "Difference (yhat_naive - yhat_full):\n",
      "[ 3.55271368e-15  1.77635684e-14  7.10542736e-15  2.13162821e-14\n",
      "  1.77635684e-14  1.42108547e-14  2.84217094e-14  2.13162821e-14\n",
      "  1.59872116e-14  1.42108547e-14  1.42108547e-14  1.06581410e-14\n",
      "  2.48689958e-14  1.42108547e-14  0.00000000e+00  1.42108547e-14\n",
      "  7.10542736e-15  1.06581410e-14  7.10542736e-15  1.06581410e-14\n",
      "  1.24344979e-14  2.13162821e-14  1.42108547e-14  1.59872116e-14\n",
      "  2.13162821e-14  1.95399252e-14  1.95399252e-14  1.24344979e-14\n",
      "  7.10542736e-15  1.42108547e-14  1.77635684e-14  1.06581410e-14\n",
      "  1.24344979e-14  1.42108547e-14  1.24344979e-14  2.48689958e-14\n",
      "  1.42108547e-14  1.42108547e-14  7.10542736e-15  2.13162821e-14\n",
      "  7.10542736e-15  1.06581410e-14  1.06581410e-14  1.42108547e-14\n",
      "  1.77635684e-14  2.13162821e-14  1.06581410e-14  1.06581410e-14\n",
      "  7.10542736e-15  2.13162821e-14  2.48689958e-14  1.06581410e-14\n",
      "  3.55271368e-15  3.55271368e-15  7.10542736e-15  1.42108547e-14\n",
      "  7.10542736e-15  2.13162821e-14  7.10542736e-15  3.55271368e-15\n",
      "  2.13162821e-14  2.13162821e-14  1.06581410e-14  1.42108547e-14\n",
      "  1.77635684e-14  2.13162821e-14  1.06581410e-14  1.42108547e-14\n",
      "  1.77635684e-14  1.42108547e-14  1.42108547e-14  1.77635684e-14\n",
      "  0.00000000e+00  2.13162821e-14  1.42108547e-14  1.06581410e-14\n",
      "  1.42108547e-14  2.13162821e-14  2.48689958e-14  7.10542736e-15\n",
      "  2.48689958e-14  1.42108547e-14  1.77635684e-14  1.42108547e-14\n",
      "  1.42108547e-14  7.10542736e-15  2.48689958e-14  1.42108547e-14\n",
      "  2.13162821e-14 -3.55271368e-15  3.55271368e-15  3.55271368e-15\n",
      "  1.77635684e-14  1.06581410e-14  2.13162821e-14  1.77635684e-14\n",
      "  1.06581410e-14  1.42108547e-14  1.42108547e-14  1.42108547e-14\n",
      "  7.10542736e-15  1.77635684e-14  1.42108547e-14  1.77635684e-14\n",
      "  2.13162821e-14  2.13162821e-14  1.06581410e-14  3.55271368e-15\n",
      "  1.06581410e-14  7.10542736e-15  1.42108547e-14  1.06581410e-14\n",
      "  2.13162821e-14  3.55271368e-15  1.06581410e-14  2.13162821e-14\n",
      "  1.42108547e-14  1.42108547e-14  2.13162821e-14  2.13162821e-14\n",
      "  1.42108547e-14  3.55271368e-15  3.55271368e-15  1.06581410e-14\n",
      "  1.06581410e-14  3.90798505e-14  1.24344979e-14  1.06581410e-14\n",
      "  0.00000000e+00  2.13162821e-14  1.06581410e-14  1.06581410e-14\n",
      "  3.55271368e-15  1.24344979e-14  8.88178420e-15  1.06581410e-14\n",
      "  7.10542736e-15  7.10542736e-15  1.77635684e-14  1.06581410e-14\n",
      "  1.24344979e-14  6.21724894e-15  1.59872116e-14  8.88178420e-15\n",
      "  1.95399252e-14  3.55271368e-15  7.10542736e-15  1.95399252e-14\n",
      "  1.42108547e-14  1.95399252e-14  7.10542736e-15  3.55271368e-15\n",
      "  1.77635684e-14  1.06581410e-14  1.06581410e-14  7.10542736e-15\n",
      "  1.42108547e-14  2.84217094e-14  1.77635684e-14  1.06581410e-14\n",
      "  2.13162821e-14  7.10542736e-15  2.13162821e-14 -7.10542736e-15\n",
      "  1.42108547e-14  1.42108547e-14  2.13162821e-14  1.77635684e-14\n",
      "  7.10542736e-15  1.42108547e-14  1.42108547e-14  7.10542736e-15\n",
      "  7.10542736e-15  1.77635684e-14  2.13162821e-14  1.77635684e-14\n",
      "  2.13162821e-14  7.10542736e-15  1.42108547e-14  2.13162821e-14\n",
      "  1.42108547e-14  1.77635684e-14  7.10542736e-15  2.13162821e-14\n",
      "  1.06581410e-14  1.77635684e-14  7.10542736e-15  1.42108547e-14\n",
      "  1.42108547e-14  7.10542736e-15  1.77635684e-14  1.06581410e-14\n",
      "  7.10542736e-15  0.00000000e+00  1.42108547e-14  2.13162821e-14\n",
      "  1.42108547e-14 -7.10542736e-15  1.42108547e-14  7.10542736e-15\n",
      "  1.06581410e-14  2.48689958e-14  3.55271368e-14  1.42108547e-14\n",
      "  1.42108547e-14  1.77635684e-14  2.13162821e-14  1.06581410e-14\n",
      "  2.48689958e-14  1.06581410e-14  2.84217094e-14  1.06581410e-14\n",
      "  1.42108547e-14  1.77635684e-14  1.06581410e-14  1.06581410e-14\n",
      "  2.13162821e-14  3.55271368e-15  1.06581410e-14  1.42108547e-14\n",
      "  2.13162821e-14  1.06581410e-14  0.00000000e+00  1.42108547e-14\n",
      "  1.42108547e-14  1.42108547e-14  1.42108547e-14  1.42108547e-14\n",
      "  7.10542736e-15  3.55271368e-15  2.48689958e-14  2.84217094e-14\n",
      "  4.26325641e-14  1.42108547e-14  1.77635684e-14  2.48689958e-14\n",
      "  7.10542736e-15  0.00000000e+00  1.42108547e-14  2.48689958e-14\n",
      "  2.13162821e-14  7.10542736e-15  1.06581410e-14  2.84217094e-14\n",
      "  1.42108547e-14  8.88178420e-15  7.10542736e-15  3.55271368e-15\n",
      "  1.42108547e-14  7.10542736e-15  1.42108547e-14  1.77635684e-14\n",
      "  3.55271368e-15  3.55271368e-15  0.00000000e+00  7.10542736e-15\n",
      "  7.10542736e-15  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  1.42108547e-14  1.42108547e-14  1.42108547e-14  7.10542736e-15\n",
      "  1.42108547e-14  7.10542736e-15  1.77635684e-14  0.00000000e+00\n",
      "  7.10542736e-15  1.06581410e-14  1.77635684e-14  3.55271368e-15\n",
      "  3.55271368e-15  2.13162821e-14  1.42108547e-14  7.10542736e-15\n",
      "  7.10542736e-15  7.10542736e-15  2.48689958e-14  2.84217094e-14\n",
      "  1.42108547e-14  2.13162821e-14  2.13162821e-14  1.42108547e-14\n",
      "  2.13162821e-14  1.42108547e-14  1.42108547e-14  2.13162821e-14\n",
      "  1.77635684e-14  2.13162821e-14  1.42108547e-14  2.84217094e-14\n",
      "  7.10542736e-15  1.42108547e-14  2.48689958e-14  1.06581410e-14\n",
      "  2.48689958e-14  1.42108547e-14  1.42108547e-14  1.42108547e-14\n",
      "  3.55271368e-15  1.77635684e-14  1.42108547e-14  1.42108547e-14\n",
      "  0.00000000e+00  1.42108547e-14  1.42108547e-14  7.10542736e-15\n",
      "  1.42108547e-14  2.13162821e-14  1.77635684e-14  1.77635684e-14\n",
      "  1.06581410e-14  1.77635684e-14  1.42108547e-14  7.10542736e-15\n",
      "  1.77635684e-14  1.77635684e-14  1.42108547e-14  1.77635684e-14\n",
      "  1.06581410e-14  1.06581410e-14  3.55271368e-15  1.06581410e-14\n",
      "  1.06581410e-14  1.42108547e-14  1.42108547e-14 -3.55271368e-15\n",
      "  2.48689958e-14  2.13162821e-14  2.13162821e-14  1.42108547e-14\n",
      "  1.06581410e-14  1.06581410e-14  0.00000000e+00  1.42108547e-14\n",
      "  1.42108547e-14  1.06581410e-14  7.10542736e-15  1.77635684e-14\n",
      "  1.42108547e-14  1.42108547e-14  3.55271368e-15  1.06581410e-14\n",
      "  7.10542736e-15  1.42108547e-14  7.10542736e-15  1.77635684e-14\n",
      "  1.42108547e-14  7.10542736e-15  7.10542736e-15  1.77635684e-14\n",
      "  1.42108547e-14  1.42108547e-14  0.00000000e+00  1.06581410e-14\n",
      "  1.77635684e-14  2.84217094e-14  1.06581410e-14  1.42108547e-14\n",
      "  7.10542736e-15  2.13162821e-14  1.06581410e-14  1.77635684e-14\n",
      "  1.42108547e-14  1.24344979e-14  1.06581410e-14  1.42108547e-14\n",
      "  7.10542736e-15  1.42108547e-14  0.00000000e+00  7.10542736e-15\n",
      "  1.42108547e-14  4.44089210e-15  1.06581410e-14  7.10542736e-15\n",
      "  2.13162821e-14  1.06581410e-14  1.06581410e-14  1.42108547e-14\n",
      " -1.95399252e-14  7.10542736e-15  5.32907052e-15  5.32907052e-15\n",
      "  6.66133815e-15  8.88178420e-15  1.15463195e-14  1.24344979e-14\n",
      "  4.44089210e-15  1.42108547e-14  1.77635684e-14  7.10542736e-15\n",
      "  1.06581410e-14  1.06581410e-14  1.06581410e-14  1.06581410e-14\n",
      "  2.13162821e-14  1.77635684e-14  9.76996262e-15  1.77635684e-14\n",
      "  1.06581410e-14  1.42108547e-14  1.06581410e-14  1.06581410e-14\n",
      "  1.33226763e-14 -1.77635684e-15  8.88178420e-15  1.06581410e-14\n",
      "  5.32907052e-15  1.77635684e-14  5.32907052e-15  1.06581410e-14\n",
      "  1.82076576e-14  1.24344979e-14 -3.55271368e-15 -1.77635684e-15\n",
      "  3.55271368e-15  1.42108547e-14  2.39808173e-14  1.42108547e-14\n",
      "  1.06581410e-14  1.06581410e-14  7.10542736e-15  1.42108547e-14\n",
      "  8.88178420e-15  7.10542736e-15  1.06581410e-14  1.59872116e-14\n",
      "  8.88178420e-15  7.10542736e-15  1.06581410e-14  1.06581410e-14\n",
      "  2.48689958e-14  7.10542736e-15  1.24344979e-14  1.24344979e-14\n",
      "  8.88178420e-15  1.24344979e-14  9.76996262e-15  1.06581410e-14\n",
      "  1.24344979e-14  1.06581410e-14  1.42108547e-14  1.06581410e-14\n",
      "  1.24344979e-14  7.10542736e-15  2.13162821e-14  1.42108547e-14\n",
      "  7.10542736e-15  7.10542736e-15  1.42108547e-14  1.42108547e-14\n",
      "  1.42108547e-14  1.06581410e-14  1.24344979e-14  1.06581410e-14\n",
      "  5.32907052e-15  1.24344979e-14  1.77635684e-14  1.42108547e-14\n",
      "  2.13162821e-14  1.42108547e-14  3.55271368e-15  7.10542736e-15\n",
      "  2.48689958e-14  1.06581410e-14  1.24344979e-14  7.10542736e-15\n",
      "  1.77635684e-14  1.42108547e-14  1.06581410e-14  7.10542736e-15\n",
      "  1.77635684e-14  1.77635684e-14  1.06581410e-14  1.06581410e-14\n",
      "  1.77635684e-14  1.59872116e-14  1.42108547e-14  3.55271368e-15\n",
      "  1.42108547e-14  7.10542736e-15  1.77635684e-14  1.06581410e-14\n",
      "  1.42108547e-14  1.77635684e-14  1.42108547e-14  1.42108547e-14\n",
      "  1.24344979e-14  8.88178420e-15  1.90958360e-14  3.55271368e-15\n",
      "  1.42108547e-14  7.10542736e-15  1.42108547e-14  3.55271368e-15\n",
      "  1.06581410e-14  1.06581410e-14  1.42108547e-14  1.06581410e-14\n",
      "  1.77635684e-14  1.06581410e-14  7.10542736e-15  1.06581410e-14\n",
      "  3.55271368e-15  3.55271368e-15]\n"
     ]
    }
   ],
   "source": [
    "# Initialize yhat_naive as zeros\n",
    "yhat_naive = np.zeros_like(y)\n",
    "\n",
    "# Project y onto each column of Q and sum\n",
    "for j in range(Q.shape[1]):\n",
    "    proj = orthogonal_projection(y, Q[:, j])\n",
    "    yhat_naive += proj['a_parallel']\n",
    "\n",
    "# Full projection using H = Q @ Qᵀ\n",
    "H = Q @ Q.T\n",
    "yhat_full = H @ y\n",
    "\n",
    "# Compare naive sum vs full projection\n",
    "if np.allclose(yhat_naive, yhat_full):\n",
    "    print(\"The naive projection (one column at a time) equals the full projection (Q @ Qᵀ @ y).\")\n",
    "else:\n",
    "    print(\"There is a discrepancy between the projections!\")\n",
    "\n",
    "# Optionally, print difference\n",
    "print(\"Difference (yhat_naive - yhat_full):\")\n",
    "print(yhat_naive - yhat_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bbb76d-1108-40bf-99c1-8eaf8ab3ba38",
   "metadata": {},
   "source": [
    "Split the Boston Housing Data into a training set and a test set where the training set is 80% of the observations. Do so at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59951734-a620-484b-9902-8bdd49d8c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (404, 14)\n",
      "X_test shape: (102, 14)\n",
      "y_train length: 404\n",
      "y_test length: 102\n"
     ]
    }
   ],
   "source": [
    "# Assume n, X, and y are already defined. For example:\n",
    "# n = X.shape[0]\n",
    "# (Make sure X is a NumPy array and y is a 1D array or similar.)\n",
    "\n",
    "np.random.seed(123)\n",
    "n_train = int(np.floor(0.8 * n))\n",
    "n_test = n - n_train\n",
    "\n",
    "indices = np.random.permutation(n)\n",
    "train_indices = indices[:n_train]\n",
    "test_indices = indices[n_train:]\n",
    "\n",
    "X_train = X[train_indices, :]\n",
    "X_test = X[test_indices, :]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train length:\", len(y_train))\n",
    "print(\"y_test length:\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2cf23-efeb-430e-a04f-c361cde984f5",
   "metadata": {},
   "source": [
    "Fit an OLS model. Find the s_e in sample and out of sample. Which one is greater? Note: we are now using s_e and not RMSE since RMSE has the n-(p + 1) in the denominator not n-1 which attempts to de-bias the error estimate by inflating the estimate when overfitting in high p. Again, we're just using `sd(e)`, the sample standard deviation of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80db879f-35ca-4023-9a30-7fa09ff1bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample s_e (sample SD of residuals): 4.540082806616528\n",
      "Out-of-sample s_e (sample SD of residuals): 5.317400950608923\n"
     ]
    }
   ],
   "source": [
    "# Fit the OLS model on the training set.\n",
    "# (Assume X_train and y_train have already been defined,\n",
    "# and that X_train already includes a constant column if needed.)\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Predict on the test set\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "# Compute in-sample standard error (sample SD of residuals from the training fit)\n",
    "in_sample_se = np.std(model.resid, ddof=1)\n",
    "\n",
    "# Compute out-of-sample standard error (sample SD of test residuals)\n",
    "out_sample_se = np.std(y_test - y_hat_test, ddof=1)\n",
    "\n",
    "print(\"In-sample s_e (sample SD of residuals):\", in_sample_se)\n",
    "print(\"Out-of-sample s_e (sample SD of residuals):\", out_sample_se)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02f4a0-209b-466c-ab17-ec7474bcb2f4",
   "metadata": {},
   "source": [
    "Do these two exercises `Nsim = 1000` times and find the average difference between s_e and ooss_e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a50414fb-9dc6-4c73-a540-534699b1df68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference (s_e - ooss_e): -0.19088290273301492\n"
     ]
    }
   ],
   "source": [
    "# Assume n, X, and y are already defined.\n",
    "# Here, n is the total number of observations.\n",
    "# X is the design matrix and y is the response vector.\n",
    "# For consistency with the R code (which uses '+0'), we will fit the model without a constant.\n",
    "# If X already has a constant column, you might need to remove it; here we assume X does NOT include one.\n",
    "\n",
    "Nsim = 1000\n",
    "n_train = int(np.floor(0.8 * n))\n",
    "n_test = n - n_train\n",
    "\n",
    "s_e_array = np.zeros(Nsim)\n",
    "oosSSE_array = np.zeros(Nsim)\n",
    "\n",
    "for i in range(Nsim):\n",
    "    indices = np.random.permutation(n)\n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "\n",
    "    X_train = X[train_indices, :]\n",
    "    X_test = X[test_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    oosSSE_array[i] = np.std(y_test - y_hat_test, ddof=1)\n",
    "    s_e_array[i] = np.std(model.resid, ddof=1)\n",
    "\n",
    "mean_diff = np.mean(s_e_array - oosSSE_array)\n",
    "print(\"Average difference (s_e - ooss_e):\", mean_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aafa5f-d4c5-4fdb-a139-98e3a6154f86",
   "metadata": {},
   "source": [
    "We'll now add random junk to the data so that `p_plus_one = n_train` and create a new data matrix `X_with_junk.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2b38a88-f31a-46e9-aedd-d2eec495f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (506, 14)\n",
      "X_with_junk shape: (506, 404)\n"
     ]
    }
   ],
   "source": [
    "# Assume X, n, n_train, and p_plus_one are already defined.\n",
    "# Create the junk matrix: with n rows and (n_train - p_plus_one) columns.\n",
    "junk = np.random.randn(n, n_train - p_plus_one)\n",
    "\n",
    "# Concatenate X and the junk matrix horizontally\n",
    "X_with_junk = np.hstack((X, junk))\n",
    "\n",
    "# Print dimensions\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"X_with_junk shape:\", X_with_junk.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafda18-b5bc-4911-aea4-90a2d1d27e3d",
   "metadata": {},
   "source": [
    "Repeat the exercise above measuring the average s_e and ooss_e but this time record these metrics by number of features used. That is, do it for the first column of `X_with_junk` (the intercept column), then do it for the first and second columns, then the first three columns, etc until you do it for all columns of `X_with_junk`. Save these in `s_e_by_p` and `ooss_e_by_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7cef0-29a4-48fe-81e8-7808dd9e011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5  # Test set is 1/5 of the data\n",
    "n_test = n // K\n",
    "n_train = n - n_test\n",
    "Nsim = 100\n",
    "\n",
    "num_features = X_with_junk.shape[1]\n",
    "\n",
    "s_e_by_p = np.zeros(num_features)\n",
    "ooss_e_by_p = np.zeros(num_features)\n",
    "\n",
    "for j in range(1, num_features + 1):\n",
    "    oosSSE_array = np.zeros(Nsim)\n",
    "    s_e_array = np.zeros(Nsim)\n",
    "    \n",
    "    for i in range(Nsim):\n",
    "        all_indices = np.random.permutation(n)\n",
    "        test_indices = all_indices[:n_test]\n",
    "        train_indices = all_indices[n_test:]\n",
    "        \n",
    "        X_train = X_with_junk[train_indices, :j]\n",
    "        X_test = X_with_junk[test_indices, :j]\n",
    "        y_train = y[train_indices]\n",
    "        y_test = y[test_indices]\n",
    "        \n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "        y_hat_test = model.predict(X_test)\n",
    "        \n",
    "        oosSSE_array[i] = np.std(y_test - y_hat_test, ddof=1)\n",
    "        s_e_array[i] = np.std(model.resid, ddof=1)\n",
    "    \n",
    "    ooss_e_by_p[j-1] = np.mean(oosSSE_array)\n",
    "    s_e_by_p[j-1] = np.mean(s_e_array)\n",
    "\n",
    "print(\"Average out-of-sample s_e by number of features:\")\n",
    "print(ooss_e_by_p)\n",
    "print(\"Average in-sample s_e by number of features:\")\n",
    "print(s_e_by_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20846e-3625-4081-9ea6-74e977e8af8e",
   "metadata": {},
   "source": [
    "You can graph them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689dae8-a476-46f0-9540-86cd78005c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_line, labs, theme_minimal\n",
    "\n",
    "# Create data frames for the in-sample and out-of-sample standard errors.\n",
    "df_in = pd.DataFrame({\n",
    "    'p': np.arange(1, len(s_e_by_p) + 1),\n",
    "    's_e': s_e_by_p,\n",
    "    'series': 'In-sample'\n",
    "})\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    'p': np.arange(1, len(ooss_e_by_p) + 1),\n",
    "    's_e': ooss_e_by_p,\n",
    "    'series': 'Out-of-sample'\n",
    "})\n",
    "\n",
    "# Combine the two dataframes\n",
    "df = pd.concat([df_in, df_out], ignore_index=True)\n",
    "\n",
    "# Create the plot using plotnine\n",
    "plot = (ggplot(df, aes(x='p', y='s_e', color='series'))\n",
    "        + geom_line()\n",
    "        + labs(x='Number of features (p)',\n",
    "               y='s_e',\n",
    "               title='In-sample vs. Out-of-sample s_e by number of features')\n",
    "        + theme_minimal()\n",
    "       )\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c5d83-d874-4717-8d94-89324d3537ba",
   "metadata": {},
   "source": [
    "Is this shape expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ef063-4883-4258-997c-f017a5123742",
   "metadata": {},
   "source": [
    "Yes this shape is expected because as we add more features the in-sample error will decrease due to the the model fitting the additional features and data. However, the out of sample error will start to get worse due to the over-fitting that is occurring. This will lead to a worse modle that produces worse predictions for data that is out of sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229ba1f-a813-467d-8a86-6ac3b9112cd3",
   "metadata": {},
   "source": [
    "Now repeat the exercise above except use 5-fold CV (K=5 cross validation) for each p. The code below will also plot the oos RMSE. This oos RMSE curve should be similar to the curve in the above problem, but now it will be more stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c8bc3-63a8-4dd7-90d9-5aa952b96aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume n, y, and X_with_junk are already defined.\n",
    "# Let p_max be the total number of features (columns) in X_with_junk.\n",
    "p_max = X_with_junk.shape[1]\n",
    "\n",
    "K = 5\n",
    "n_test = n // K\n",
    "\n",
    "# Create a folds array: assign each observation to one of K folds.\n",
    "# Replicate 1:K enough times, then shuffle.\n",
    "folds = np.tile(np.arange(K), n // K + 1)[:n]\n",
    "np.random.shuffle(folds)\n",
    "\n",
    "# Initialize a matrix to store the out-of-sample RMSE for each model size and fold.\n",
    "ooss_e_by_p_k = np.zeros((p_max, K))\n",
    "\n",
    "for j in range(1, p_max + 1):\n",
    "    for k in range(K):\n",
    "        test_indices = np.where(folds == k)[0]\n",
    "        train_indices = np.where(folds != k)[0]\n",
    "        \n",
    "        X_train = X_with_junk[train_indices, :j]\n",
    "        X_test = X_with_junk[test_indices, :j]\n",
    "        y_train = y[train_indices]\n",
    "        y_test = y[test_indices]\n",
    "        \n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        ooss_e_by_p_k[j-1, k] = np.sqrt(np.mean((y_test - y_hat)**2))\n",
    "\n",
    "# For each model size (row), compute the standard deviation of the RMSE over the K folds.\n",
    "s_e_by_p = np.std(ooss_e_by_p_k, axis=1)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    'p': np.arange(1, p_max + 1),\n",
    "    's_e': s_e_by_p\n",
    "})\n",
    "\n",
    "# Plot using plotnine\n",
    "plot = (ggplot(df_plot, aes(x='p', y='s_e'))\n",
    "        + geom_line()\n",
    "        + labs(x=\"Number of Features\", y=\"OOS RMSE (sd)\", title=\"5-fold CV OOS RMSE vs. Number of Features\")\n",
    "        + theme_minimal())\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2321b-3537-4bb9-8b7e-f24fdf5c4419",
   "metadata": {},
   "source": [
    "Even though the concept of confidence intervals (CIs) will not be on the midterm, construct 95% CIs for each of the oosRMSE measurements by number of features, p. A CI is a real-number interval with a lower bound and upper bound. The formula for the CI is [s_e - 2 * s_s_e, s_e + 2 * s_s_e]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f25d85-53c0-4b1d-b4dc-6edb85664970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean out-of-sample RMSE for each model size (row-wise mean)\n",
    "mean_oos = np.mean(ooss_e_by_p_k, axis=1)\n",
    "\n",
    "# Compute the sample standard deviation for each model size (across simulations)\n",
    "sd_oos = np.std(ooss_e_by_p_k, axis=1)\n",
    "\n",
    "# Construct the 95% confidence intervals\n",
    "CI_lower = mean_oos - 2 * sd_oos\n",
    "CI_upper = mean_oos + 2 * sd_oos\n",
    "\n",
    "# Create a DataFrame with the number of features and the CI bounds.\n",
    "df_CI = pd.DataFrame({\n",
    "    'p': np.arange(1, p_max + 1),\n",
    "    'mean_oos': mean_oos,\n",
    "    'CI_lower': CI_lower,\n",
    "    'CI_upper': CI_upper\n",
    "})\n",
    "\n",
    "print(df_CI)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
